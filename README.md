# FakeNewsClassification

## Описание проекта
**FakeNewsClassification** — это проект для автоматического определения фейковых новостей с использованием методов обработки естественного языка (NLP) и машинного обучения. Проект основан на датасете, содержащем статьи с метками "фейк" и "правда", и исследует различные подходы к векторизации текста и классификации для достижения высокой точности.

Цель проекта — сравнить эффективность трёх методов векторизации (TF-IDF, Word2Vec, BERT) и их комбинаций с классическими и нейросетевыми моделями, чтобы выявить оптимальный подход для классификации новостей.

## Особенности
- **Датасет**:
  - `Fake.csv` (23,502 фейковых новостей).
  - `True.csv` (21,417 правдивых новостей).
  - Колонки: `title`, `text`, `subject`, `date`.
- **Предобработка текста**:
  - Удаление стоп-слов, пунктуации, приведение к нижнему регистру.
  - Лемматизация с использованием `spaCy` для сохранения семантики.
- **Методы векторизации**:
  - **TF-IDF**: Статистическая мера для создания разреженных векторов.
  - **Word2Vec**: Плотные векторы с учётом семантических связей слов.
  - **BERT**: Контекстно-зависимые эмбеддинги для глубокого понимания текста.
- **Модели классификации**:
  - **CatBoost**: Градиентный бустинг для TF-IDF и Word2Vec с поддержкой GPU.
  - **Нейросеть на PyTorch**: Полносвязная сеть поверх BERT-эмбеддингов.
- **Оценка качества**:
  - Метрики: Accuracy, F1-score, Precision, Recall.
  - Результаты собраны в DataFrame для сравнения методов.
- **Технологии**:
  - Python, pandas, scikit-learn, nltk, spaCy, gensim, transformers, torch, catboost.

## Требования
- **Python**: 3.9 или выше.
- **Библиотеки** (см. `requirements.txt`):
  ```
  pandas==2.0.3
  scikit-learn==1.5.0
  nltk==3.8.1
  spacy==3.7.2
  gensim==4.3.2
  transformers==4.35.2
  torch==2.0.1
  catboost==1.2.5
  ```
- **Датасет**: Файлы `Fake.csv` и `True.csv` должны быть в папке проекта.
- **Аппаратное обеспечение**: GPU рекомендуется для BERT и CatBoost.

## Структура проекта
```
FakeNewsClassification/
│
├── fake_news_classification.ipynb             # Основной скрипт для предобработки, векторизации и обучения
├── requirements.txt     # Список зависимостей
├── processed_news.csv   # (Создаётся) Предобработанный датасет
├── Fake.csv            # (Требуется) Датасет фейковых новостей
├── True.csv            # (Требуется) Датасет правдивых новостей
└── README.md           # Документация проекта
```

## Результаты
Проект сравнивает три подхода:
- **TF-IDF + CatBoost**: Быстрый и точный метод, подходящий для больших данных.
- **Word2Vec + CatBoost**: Учитывает семантику, но может терять контекст из-за усреднения.
- **BERT + Нейросеть**: Даёт высокую точность благодаря глубокому пониманию текста, но требует больше ресурсов.

Метрики (Accuracy, F1-score, Precision, Recall) для всех моделей можно посмотреть в `fake_news_classification.ipynb` для анализа.

## Примечания
- **Ограничения**: BERT требует GPU для быстрого обучения. Для тестов использовалось подмножество данных (5000 примеров), но код масштабируется на полный датасет.
- **Расширения**: Проект можно дополнить:
  - Интеграцией в Telegram-бот для проверки новостей в реальном времени.
  - Веб-интерфейсом на Flask/Streamlit.
  - Браузерным расширением для анализа текста на страницах.
- **Дальнейшая работа**: Настройка гиперпараметров CatBoost, дообучение BERT на полном датасете, исследование других моделей (например, RoBERTa).
- **Лицензия**: [MIT] (уточните, если хотите другую).

---
